{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib import cbook\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "task_data = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../../src/data/evaluation\"\n",
    "TEST_PATH = f\"../../src/data/acs_{task_data}/processed/acs_{task_data}_test.csv\"\n",
    "\n",
    "BASELINE = f\"{DATA_PATH}/baseline/{task_data}\"\n",
    "SEPARATION = f\"{DATA_PATH}/hardt2016/{task_data}\"\n",
    "INDENPENDENCE = f\"{DATA_PATH}/kamiran_calders2012/{task_data}\"\n",
    "SUFFICIENCY = f\"{DATA_PATH}/pleiss2017/{task_data}/calib_weighted\"\n",
    "\n",
    "base_pred = pd.read_csv(f\"{BASELINE}/XGBClassifier_predictions.csv\")\n",
    "sep_pred = pd.read_csv(f\"{SEPARATION}/XGBClassifier_separation_predictions.csv\")\n",
    "ind_pred = pd.read_csv(f\"{INDENPENDENCE}/XGBClassifier_independence_predictions.csv\")\n",
    "suf_pred = pd.read_csv(f\"{SUFFICIENCY}/XGBClassifier_sufficiency_predictions.csv\")\n",
    "\n",
    "base_scores = np.load(f\"{BASELINE}/XGBClassifier_scores.npy\", allow_pickle=True).item()\n",
    "base_scores_cond = np.load(f\"{BASELINE}/XGBClassifier_conditional_scores.npy\", allow_pickle=True).item()\n",
    "\n",
    "sep_scores = np.load(f\"{SEPARATION}/XGBClassifier_scores_separation.npy\", allow_pickle=True).item()\n",
    "sep_scores_cond = np.load(f\"{SEPARATION}/XGBClassifier_conditional_scores_separation.npy\", allow_pickle=True).item()\n",
    "\n",
    "ind_scores = np.load(f\"{INDENPENDENCE}/XGBClassifier_scores_independence.npy\", allow_pickle=True).item()\n",
    "ind_scores_cond = np.load(\n",
    "    f\"{INDENPENDENCE}/XGBClassifier_conditional_scores_independence.npy\", allow_pickle=True\n",
    ").item()\n",
    "\n",
    "suf_scores = np.load(f\"{SUFFICIENCY}/XGBClassifier_scores_sufficiency.npy\", allow_pickle=True).item()\n",
    "suf_scores_cond = np.load(f\"{SUFFICIENCY}/XGBClassifier_conditional_scores_sufficiency.npy\", allow_pickle=True).item()\n",
    "\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading as dataframes\n",
    "\n",
    "df_base = pd.DataFrame.from_dict(base_scores, orient=\"index\")\n",
    "df_base_cond = pd.DataFrame.from_dict(base_scores_cond, orient=\"index\")\n",
    "\n",
    "df_suf = pd.DataFrame.from_dict(suf_scores, orient=\"index\")\n",
    "df_suf_cond = pd.DataFrame.from_dict(suf_scores_cond, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "colors = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "box_colors = plt.get_cmap(\"Set3\")\n",
    "box_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_cond[\"PRIV_PPV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are most worried about being unfair to people without assistance (rejected loan applicants),\n",
    "# the best fairness metric would be something called False Omission Rate (FOR) parity.\n",
    "# (Since FOR = 1-NPV, this metric also relates to the Sufficiency criterion.)\n",
    "\n",
    "# Looking at FOR values, we see that 43% of women the model predicted to default actually would have\n",
    "# paid back their loan – exactly the same proportion as among men. Even though the model falsely omits\n",
    "# (or wrongly denies) 43 percent of female and male loan applicants from actually getting loans, it\n",
    "# treats men and women the same. Therefore, in this case, if we focus on FOR as our fairness metric\n",
    "# and females as our protected demographic group, we can confirm that our ML assisted credit scoring\n",
    "# decisions do not show “any prejudice or favoritism toward an individual or group”. Fairness can be\n",
    "# measured – once the right fairness definition to use has been identified by us.\n",
    "\n",
    "# requires that the positive and negative predictive values are the same. Values such as the true\n",
    "# positive rate and the positive predictive rate are easy to calculate for different populations,\n",
    "# and they can be simply read off a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_cond[\"UNP_PPV\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"baseline\", \"calibration \\n info_withholding\"]\n",
    "legend_labels = [\"Females\", \"Males\"]\n",
    "\n",
    "\n",
    "ax1_data_lists = [\n",
    "    (df_base_cond[\"UNP_PPV\"].values, df_base_cond[\"PRIV_PPV\"].values),\n",
    "    (df_suf_cond[\"UNP_PPV\"].values, df_suf_cond[\"PRIV_PPV\"].values),\n",
    "]\n",
    "\n",
    "print(\"PPV means baseline:\", df_base_cond[\"UNP_PPV\"].mean(), df_base_cond[\"PRIV_PPV\"].mean())\n",
    "print(\"PPV means sufficiency:\", df_suf_cond[\"UNP_PPV\"].mean(), df_suf_cond[\"PRIV_PPV\"].mean())\n",
    "\n",
    "ax2_data_lists = [\n",
    "    (df_base_cond[\"UNP_NPV\"].values, df_base_cond[\"PRIV_NPV\"].values),\n",
    "    (df_suf_cond[\"UNP_NPV\"].values, df_suf_cond[\"PRIV_NPV\"].values),\n",
    "]\n",
    "\n",
    "print(\"NPV means baseline:\", df_base_cond[\"UNP_NPV\"].mean(), df_base_cond[\"PRIV_NPV\"].mean())\n",
    "print(\"NPV means sufficiency:\", df_suf_cond[\"UNP_NPV\"].mean(), df_suf_cond[\"PRIV_NPV\"].mean())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.3))\n",
    "# fig, ax1 = plt.subplots(figsize=(5, 4.5))\n",
    "\n",
    "num_groups = len(ax1_data_lists)\n",
    "group_width = 1\n",
    "box_width = group_width / 4\n",
    "positions = np.arange(num_groups)\n",
    "\n",
    "box_properties = {\n",
    "    \"patch_artist\": True,\n",
    "    \"showfliers\": False,\n",
    "    \"medianprops\": {\"color\": \"black\"},\n",
    "    \"whiskerprops\": {\"color\": \"black\"},\n",
    "    \"capprops\": {\"color\": \"black\"},\n",
    "    \"flierprops\": {\"markeredgecolor\": \"black\"},\n",
    "    \"showmeans\": True,\n",
    "    \"meanprops\": {\"marker\": \"o\", \"markerfacecolor\": \"white\", \"markeredgecolor\": \"black\", \"markersize\": 4},\n",
    "}\n",
    "\n",
    "for i, (data1, data2) in enumerate(ax1_data_lists):\n",
    "\n",
    "    # generate stats for the boxplot\n",
    "    stats1 = cbook.boxplot_stats([data1], labels=[labels[0]])\n",
    "    stats2 = cbook.boxplot_stats([data2], labels=[labels[1]])\n",
    "\n",
    "    # Plot the boxplot statistics using bxp\n",
    "    bp1 = ax1.bxp(stats1, positions=[positions[i] - box_width / 2], widths=box_width, **box_properties)\n",
    "    bp2 = ax1.bxp(stats2, positions=[positions[i] + box_width / 2], widths=box_width, **box_properties)\n",
    "\n",
    "    for patch in bp1[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(3))\n",
    "    for patch in bp2[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(4))\n",
    "\n",
    "    # get the limit of the y-axis\n",
    "    y_max = max(data1.max(), data2.max())\n",
    "    y_max = y_max + 0.0015\n",
    "    # Adding the significance bar\n",
    "    x1 = positions[i] - box_width / 2 - 0.02\n",
    "    x2 = positions[i] + box_width / 2 + 0.02\n",
    "    y, h, color = y_max, 0.001, \"#3D3D3D\"  # Adjust these values based on your plot scale\n",
    "\n",
    "    # Plot the significance bar\n",
    "    ax1.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.0, c=color)\n",
    "    # ax2.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    if i == 0:\n",
    "        ax1.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    else:\n",
    "        ax1.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "\n",
    "    # Add separator line between pairs, except after the last pair\n",
    "    if i < num_groups - 1:\n",
    "        ax1.axvline(x=positions[i] + 0.5, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# ax1.set_yticks([0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.21])\n",
    "# ax1.set_ylim(0.08, 0.21)\n",
    "ax1.set_xticks(positions)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.set_ylabel(\"error rates scale\")\n",
    "ax1.set_title(\"positive predictive values across groups\", fontsize=10)\n",
    "\n",
    "\n",
    "for i, (data1, data2) in enumerate(ax2_data_lists):\n",
    "    # generate stats for the boxplot\n",
    "    stats1 = cbook.boxplot_stats([data1], labels=[labels[0]])\n",
    "    stats2 = cbook.boxplot_stats([data2], labels=[labels[1]])\n",
    "\n",
    "    # Plot the boxplot statistics using bxp\n",
    "    bp1 = ax2.bxp(stats1, positions=[positions[i] - box_width / 2], widths=box_width, **box_properties)\n",
    "    bp2 = ax2.bxp(stats2, positions=[positions[i] + box_width / 2], widths=box_width, **box_properties)\n",
    "\n",
    "    for patch in bp1[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(3))\n",
    "    for patch in bp2[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(4))\n",
    "\n",
    "    # get the limit of the y-axis\n",
    "    y_max = max(data1.max(), data2.max())\n",
    "    y_max = y_max + 0.0015\n",
    "    # Adding the significance bar\n",
    "    x1 = positions[i] - box_width / 2 - 0.02\n",
    "    x2 = positions[i] + box_width / 2 + 0.02\n",
    "    y, h, color = y_max, 0.001, \"#3D3D3D\"  # Adjust these values based on your plot scale\n",
    "\n",
    "    # Plot the significance bar\n",
    "    ax2.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.0, c=color)\n",
    "    # ax2.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    if i == 0:\n",
    "        ax2.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    else:\n",
    "        ax2.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "\n",
    "    if i < num_groups - 1:\n",
    "        ax2.axvline(x=positions[i] + 0.5, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "ax2.set_xticks(positions)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.set_ylabel(\"error rates scale\")\n",
    "ax2.set_title(\"negative predictive values across groups\", fontsize=10)\n",
    "\n",
    "first_legend = ax2.legend(labels=legend_labels, bbox_to_anchor=(1.04, 1), title=\"sensitive groups\", loc=\"upper left\")\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"* p < 0.05\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"** p < 0.01\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"*** p < 0.001\"),\n",
    "]\n",
    "\n",
    "# Adding the custom legend to the plot\n",
    "# Add the second legend to the same axis, but outside of the plot\n",
    "second_legend = ax2.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 0.75),\n",
    "    ncol=1,\n",
    "    title=\"significance levels\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax2.add_artist(first_legend)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"../assets/boxplot_ppv.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(\"../assets/boxplot_fdr.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"baseline\", \"calibration \\n info_withholding\"]\n",
    "legend_labels = [\"Females\", \"Males\"]\n",
    "\n",
    "ax1_data_lists = [\n",
    "    (df_base_cond[\"UNP_FOR\"].values, df_base_cond[\"PRIV_FOR\"].values),\n",
    "    (df_suf_cond[\"UNP_FOR\"].values, df_suf_cond[\"PRIV_FOR\"].values),\n",
    "]\n",
    "\n",
    "# If we are most worried about being unfair to people without assistance (rejected loan applicants),\n",
    "# the best fairness metric would be something called False Omission Rate (FOR) parity.\n",
    "# (Since FOR = 1-NPV, this metric also relates to the Sufficiency criterion.)\n",
    "\n",
    "# Looking at FOR values, we see that 43% of women the model predicted to default actually would have\n",
    "# paid back their loan – exactly the same proportion as among men. Even though the model falsely omits\n",
    "# (or wrongly denies) 43 percent of female and male loan applicants from actually getting loans, it\n",
    "# treats men and women the same. Therefore, in this case, if we focus on FOR as our fairness metric\n",
    "# and females as our protected demographic group, we can confirm that our ML assisted credit scoring\n",
    "# decisions do not show “any prejudice or favoritism toward an individual or group”. Fairness can be\n",
    "# measured – once the right fairness definition to use has been identified by us.\n",
    "\n",
    "ax2_data_lists = [\n",
    "    (df_base_cond[\"UNP_FDR\"].values, df_base_cond[\"PRIV_FDR\"].values),\n",
    "    (df_suf_cond[\"UNP_FDR\"].values, df_suf_cond[\"PRIV_FDR\"].values),\n",
    "]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.3))\n",
    "# fig, ax1 = plt.subplots(figsize=(5, 4.5))\n",
    "\n",
    "num_groups = len(ax1_data_lists)\n",
    "group_width = 1\n",
    "box_width = group_width / 4\n",
    "positions = np.arange(num_groups)\n",
    "\n",
    "box_properties = {\n",
    "    \"patch_artist\": True,\n",
    "    \"showfliers\": False,\n",
    "    \"medianprops\": {\"color\": \"black\"},\n",
    "    \"whiskerprops\": {\"color\": \"black\"},\n",
    "    \"capprops\": {\"color\": \"black\"},\n",
    "    \"flierprops\": {\"markeredgecolor\": \"black\"},\n",
    "}\n",
    "\n",
    "for i, (data1, data2) in enumerate(ax1_data_lists):\n",
    "\n",
    "    # generate stats for the boxplot\n",
    "    stats1 = cbook.boxplot_stats([data1], labels=[labels[0]])\n",
    "    stats2 = cbook.boxplot_stats([data2], labels=[labels[1]])\n",
    "\n",
    "    # Plot the boxplot statistics using bxp\n",
    "    bp1 = ax1.bxp(stats1, positions=[positions[i] - box_width / 2], widths=box_width, **box_properties)\n",
    "    bp2 = ax1.bxp(stats2, positions=[positions[i] + box_width / 2], widths=box_width, **box_properties)\n",
    "\n",
    "    for patch in bp1[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(3))\n",
    "    for patch in bp2[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(4))\n",
    "\n",
    "    # get the limit of the y-axis\n",
    "    y_max = max(data1.max(), data2.max())\n",
    "    y_max = y_max + 0.0015\n",
    "    # Adding the significance bar\n",
    "    x1 = positions[i] - box_width / 2 - 0.02\n",
    "    x2 = positions[i] + box_width / 2 + 0.02\n",
    "    y, h, color = y_max, 0.001, \"#3D3D3D\"  # Adjust these values based on your plot scale\n",
    "\n",
    "    # Plot the significance bar\n",
    "    ax1.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.0, c=color)\n",
    "    # ax2.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    if i == 0:\n",
    "        ax1.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    else:\n",
    "        ax1.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "\n",
    "    # Add separator line between pairs, except after the last pair\n",
    "    if i < num_groups - 1:\n",
    "        ax1.axvline(x=positions[i] + 0.5, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# ax1.set_yticks([0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.21])\n",
    "# ax1.set_ylim(0.08, 0.21)\n",
    "ax1.set_xticks(positions)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.yaxis.grid(True)\n",
    "ax1.set_ylabel(\"error rates scale\")\n",
    "ax1.set_title(\"false omission rates across groups\", fontsize=10)\n",
    "\n",
    "\n",
    "for i, (data1, data2) in enumerate(ax2_data_lists):\n",
    "    # generate stats for the boxplot\n",
    "    stats1 = cbook.boxplot_stats([data1], labels=[labels[0]])\n",
    "    stats2 = cbook.boxplot_stats([data2], labels=[labels[1]])\n",
    "\n",
    "    # Plot the boxplot statistics using bxp\n",
    "    bp1 = ax2.bxp(stats1, positions=[positions[i] - box_width / 2], widths=box_width, **box_properties)\n",
    "    bp2 = ax2.bxp(stats2, positions=[positions[i] + box_width / 2], widths=box_width, **box_properties)\n",
    "\n",
    "    for patch in bp1[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(3))\n",
    "    for patch in bp2[\"boxes\"]:\n",
    "        patch.set_facecolor(box_colors(4))\n",
    "\n",
    "    # get the limit of the y-axis\n",
    "    y_max = max(data1.max(), data2.max())\n",
    "    y_max = y_max + 0.0015\n",
    "    # Adding the significance bar\n",
    "    x1 = positions[i] - box_width / 2 - 0.02\n",
    "    x2 = positions[i] + box_width / 2 + 0.02\n",
    "    y, h, color = y_max, 0.001, \"#3D3D3D\"  # Adjust these values based on your plot scale\n",
    "\n",
    "    # Plot the significance bar\n",
    "    ax2.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.0, c=color)\n",
    "    # ax2.text((x1 + x2) * 0.5, y + h, \"**\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    if i == 0:\n",
    "        ax2.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "    else:\n",
    "        ax2.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "\n",
    "    if i < num_groups - 1:\n",
    "        ax2.axvline(x=positions[i] + 0.5, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "ax2.set_xticks(positions)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.yaxis.grid(True)\n",
    "ax2.set_ylabel(\"error rates scale\")\n",
    "ax2.set_title(\"false discovery rates across groups\", fontsize=10)\n",
    "\n",
    "first_legend = ax2.legend(labels=legend_labels, bbox_to_anchor=(1.04, 1), title=\"sensitive groups\", loc=\"upper left\")\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"* p < 0.05\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"** p < 0.01\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"*** p < 0.001\"),\n",
    "]\n",
    "\n",
    "# Adding the custom legend to the plot\n",
    "# Add the second legend to the same axis, but outside of the plot\n",
    "second_legend = ax2.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 0.75),\n",
    "    ncol=1,\n",
    "    title=\"significance levels\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax2.add_artist(first_legend)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"../assets/boxplot_ppv.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(\"../assets/boxplot_fdr.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "colors = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "labels = [\"baseline\", \"calibration \\n info_withholding\"]\n",
    "suf_pred_values = [df_base[\"AVG_PRED_VALUE_DIFF\"].values, df_suf[\"AVG_PRED_VALUE_DIFF\"].values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4.5))\n",
    "\n",
    "num_groups = len(suf_pred_values)\n",
    "group_width = 1\n",
    "box_width = group_width / 3\n",
    "positions = np.arange(num_groups)\n",
    "\n",
    "box_properties = {\n",
    "    \"patch_artist\": True,\n",
    "    \"showfliers\": False,\n",
    "    \"medianprops\": {\"color\": \"black\"},\n",
    "    \"whiskerprops\": {\"color\": \"black\"},\n",
    "    \"capprops\": {\"color\": \"black\"},\n",
    "    \"flierprops\": {\"markeredgecolor\": \"black\"},\n",
    "}\n",
    "\n",
    "print(suf_pred_values[0], suf_pred_values[1])\n",
    "# independence\n",
    "stats1 = cbook.boxplot_stats([suf_pred_values[0]], labels=[\"base\"])\n",
    "stats2 = cbook.boxplot_stats([suf_pred_values[1]], labels=[\"suf\"])\n",
    "bp1 = ax.bxp(stats1, positions=[positions[i] - box_width / 2], widths=box_width, **box_properties)\n",
    "bp2 = ax.bxp(stats2, positions=[positions[i] + box_width / 2], widths=box_width, **box_properties)\n",
    "\n",
    "for patch in bp1[\"boxes\"]:\n",
    "    patch.set_facecolor(colors(0))\n",
    "for patch in bp2[\"boxes\"]:\n",
    "    patch.set_facecolor(colors(2))\n",
    "\n",
    "# ax.set_xticks([])\n",
    "ax.yaxis.grid(True)\n",
    "# ax.set_xlabel(\"reweighting\")\n",
    "ax.set_ylabel(\"error rates scale\")\n",
    "ax.set_title(\"average predictive values difference\", fontsize=10)\n",
    "\n",
    "# Adding the significance bar\n",
    "x1 = positions[i] - box_width / 2 - 0.02\n",
    "x2 = positions[i] + box_width / 2 + 0.02\n",
    "\n",
    "# # Plot the significance bar\n",
    "# y_max = max(suf_pred_values[0].max(), suf_pred_values[1].max())\n",
    "# y_max = y_max + 0.003\n",
    "# y, h, color = y_max, 0.003, \"#3D3D3D\"  # Adjust these values based on your plot scale\n",
    "# ax.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.0, c=color)\n",
    "# ax.text((x1 + x2) * 0.5, y + h, \"***\", ha=\"center\", va=\"bottom\", color=\"black\")\n",
    "\n",
    "# Adding the custom legend to the plot\n",
    "first_legend = ax.legend(labels=labels, bbox_to_anchor=(1.04, 1), title=\"intervention\", loc=\"upper left\")\n",
    "\n",
    "text_properties = {\n",
    "    \"horizontalalignment\": \"right\",\n",
    "    \"verticalalignment\": \"top\",\n",
    "    \"color\": \"red\",\n",
    "    # \"fontweight\": \"bold\",\n",
    "}\n",
    "# Add annotations\n",
    "ax.text(-0.01, 1.02, \"fair\", transform=ax.transAxes, **text_properties)\n",
    "ax.text(-0.01, 0.05, \"unfair\", transform=ax.transAxes, **text_properties)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"* p < 0.05\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"** p < 0.01\"),\n",
    "    Line2D([0], [0], marker=\"None\", color=\"none\", lw=1.0, label=\"*** p < 0.001\"),\n",
    "]\n",
    "\n",
    "# Add the second legend to the same axis, but outside of the plot\n",
    "second_legend = ax.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 0.75),\n",
    "    ncol=1,\n",
    "    title=\"significance levels\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax.add_artist(first_legend)\n",
    "# ax.add_artist(second_legend)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"../assets/boxplot_spd.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
