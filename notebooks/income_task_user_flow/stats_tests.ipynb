{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = \"income\"\n",
    "\n",
    "# scores loading\n",
    "\n",
    "DATA_PATH = \"../../src/data/evaluation\"\n",
    "TEST_PATH = f\"../../src/data/acs_{task_data}/processed/acs_{task_data}_test.csv\"\n",
    "\n",
    "BASELINE = f\"{DATA_PATH}/baseline/{task_data}\"\n",
    "SEPARATION = f\"{DATA_PATH}/hardt2016/{task_data}\"\n",
    "INDENPENDENCE = f\"{DATA_PATH}/kamiran_calders2012/{task_data}\"\n",
    "SUFFICIENCY = f\"{DATA_PATH}/pleiss2017/{task_data}/calib_weighted\"\n",
    "\n",
    "base_pred = pd.read_csv(f\"{BASELINE}/XGBClassifier_predictions.csv\")\n",
    "sep_pred = pd.read_csv(f\"{SEPARATION}/XGBClassifier_separation_predictions.csv\")\n",
    "ind_pred = pd.read_csv(f\"{INDENPENDENCE}/XGBClassifier_independence_predictions.csv\")\n",
    "suf_pred = pd.read_csv(f\"{SUFFICIENCY}/XGBClassifier_sufficiency_predictions.csv\")\n",
    "\n",
    "base_scores = np.load(f\"{BASELINE}/XGBClassifier_scores.npy\", allow_pickle=True).item()\n",
    "base_scores_cond = np.load(f\"{BASELINE}/XGBClassifier_conditional_scores.npy\", allow_pickle=True).item()\n",
    "\n",
    "sep_scores = np.load(f\"{SEPARATION}/XGBClassifier_scores_separation.npy\", allow_pickle=True).item()\n",
    "sep_scores_cond = np.load(f\"{SEPARATION}/XGBClassifier_conditional_scores_separation.npy\", allow_pickle=True).item()\n",
    "\n",
    "ind_scores = np.load(f\"{INDENPENDENCE}/XGBClassifier_scores_independence.npy\", allow_pickle=True).item()\n",
    "ind_scores_cond = np.load(\n",
    "    f\"{INDENPENDENCE}/XGBClassifier_conditional_scores_independence.npy\", allow_pickle=True\n",
    ").item()\n",
    "\n",
    "suf_scores = np.load(f\"{SUFFICIENCY}/XGBClassifier_scores_sufficiency.npy\", allow_pickle=True).item()\n",
    "suf_scores_cond = np.load(f\"{SUFFICIENCY}/XGBClassifier_conditional_scores_sufficiency.npy\", allow_pickle=True).item()\n",
    "\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading as dataframes\n",
    "\n",
    "df_base = pd.DataFrame.from_dict(base_scores, orient=\"index\")\n",
    "df_base_cond = pd.DataFrame.from_dict(base_scores_cond, orient=\"index\")\n",
    "\n",
    "df_sep = pd.DataFrame.from_dict(sep_scores, orient=\"index\")\n",
    "df_sep_cond = pd.DataFrame.from_dict(sep_scores_cond, orient=\"index\")\n",
    "\n",
    "df_ind = pd.DataFrame.from_dict(ind_scores, orient=\"index\")\n",
    "df_ind_cond = pd.DataFrame.from_dict(ind_scores_cond, orient=\"index\")\n",
    "\n",
    "df_suf = pd.DataFrame.from_dict(suf_scores, orient=\"index\")\n",
    "df_suf_cond = pd.DataFrame.from_dict(suf_scores_cond, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval(scores):\n",
    "    from scipy import stats\n",
    "\n",
    "    mean = scores.mean()\n",
    "    sem = stats.sem(scores)\n",
    "    ci = stats.t.interval(0.95, len(scores) - 1, loc=mean, scale=sem)\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_metrics = [\"AVG_ODDS_DIFF\", \"STAT_PAR_DIFF\", \"AVG_PRED_VALUE_DIFF\", \"EQ_OPP_DIFF\", \"FDR\"]\n",
    "for metric in fairness_metrics:\n",
    "    print(metric)\n",
    "\n",
    "    metric_mean = df_base[metric].mean()\n",
    "    ci = get_confidence_interval(df_base[metric])\n",
    "    print(f\"Baseline: {round(metric_mean, 3)} $\\pm$ {round(np.abs(metric_mean - ci[0]), 4)}\")\n",
    "\n",
    "    metric_mean = df_sep[metric].mean()\n",
    "    ci = get_confidence_interval(df_sep[metric])\n",
    "    print(f\"Separation: {round(metric_mean, 3)} $\\pm$ {round(np.abs(metric_mean - ci[0]), 4)}\")\n",
    "\n",
    "    metric_mean = df_ind[metric].mean()\n",
    "    ci = get_confidence_interval(df_ind[metric])\n",
    "    print(f\"Independence: {round(metric_mean, 3)} $\\pm$ {round(np.abs(metric_mean - ci[0]), 4)}\")\n",
    "\n",
    "    metric_mean = df_suf[metric].mean()\n",
    "    ci = get_confidence_interval(df_suf[metric])\n",
    "    print(f\"Sufficiency: {round(metric_mean, 3)} $\\pm$ {round(np.abs(metric_mean - ci[0]), 4)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the baseline evaluation\n",
    "# performance = [\"BAL_ACC\", \"PPV\", \"TPR\", \"F1_MACRO\"]\n",
    "performance = [\"BAL_ACC\", \"F1_MACRO\"]\n",
    "for metric in performance:\n",
    "    metric_mean = df_base[metric].mean()\n",
    "    ci = get_confidence_interval(df_base[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "\n",
    "    print(\n",
    "        f\"Baseline {metric}: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the separation evaluation - post process\n",
    "# performance = [\"BAL_ACC\", \"PPV\", \"TPR\", \"F1_MACRO\"]\n",
    "performance = [\"BAL_ACC\", \"F1_MACRO\"]\n",
    "\n",
    "for metric in performance:\n",
    "    metric_mean = df_sep[metric].mean()\n",
    "    ci = get_confidence_interval(df_sep[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "\n",
    "    print(\n",
    "        \"SEPARATION - hardt2016 - PostProcess\",\n",
    "        f\"{metric},  mean: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the independence evaluation - pre process\n",
    "# performance = [\"BAL_ACC\", \"PPV\", \"TPR\", \"F1_MACRO\"]\n",
    "performance = [\"BAL_ACC\", \"F1_MACRO\"]\n",
    "\n",
    "for metric in performance:\n",
    "    metric_mean = df_ind[metric].mean()\n",
    "    ci = get_confidence_interval(df_ind[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "\n",
    "    print(\n",
    "        \"INDEPENDENCE - kamiran_calders2012 - PreProcess\",\n",
    "        f\"{metric},  mean: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the sufficiency evaluation - post process\n",
    "# performance = [\"BAL_ACC\", \"PPV\", \"TPR\", \"F1_MACRO\"]\n",
    "performance = [\"BAL_ACC\", \"F1_MACRO\"]\n",
    "\n",
    "for metric in performance:\n",
    "    metric_mean = df_suf[metric].mean()\n",
    "    ci = get_confidence_interval(df_suf[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "\n",
    "    print(\n",
    "        \"SUFFICIENCY - pleiss2017 - PostProcess\",\n",
    "        f\"{metric},  mean: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-test, p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check significance values for the fairness metrics\n",
    "def p_value_test(x, y):\n",
    "    t_test = ttest_ind(x, y)\n",
    "    # Mann-Whitney U tests for both sets of values\n",
    "    mannwhitney = mannwhitneyu(x, y)\n",
    "\n",
    "    print(f\"T-test p-value: {t_test.pvalue:.30f}\")\n",
    "    print(f\"Mann-Whitney U-test p-value: {mannwhitney.pvalue:.30f}\")\n",
    "    return t_test.pvalue, mannwhitney.pvalue\n",
    "\n",
    "\n",
    "def significance_level(p_value):\n",
    "\n",
    "    if p_value <= 0.0001:\n",
    "        return \"**** Highly significant difference\"\n",
    "    elif 0.0001 < p_value <= 0.001:\n",
    "        return \"*** Highly significant difference\"\n",
    "    elif 0.001 < p_value <= 0.01:\n",
    "        return \"** Moderately significant difference\"\n",
    "    elif 0.01 < p_value <= 0.05:\n",
    "        return \"* Significant difference\"\n",
    "    else:\n",
    "        return \"n.s. Not significant\"\n",
    "\n",
    "\n",
    "def _significance_level(x, y):\n",
    "    U, p_value = mannwhitneyu(x, y)\n",
    "    print(f\"U: {U}, p-value: {p_value}\")\n",
    "\n",
    "    levels = [\n",
    "        (0.0001, \"**** Extremely significant difference\"),\n",
    "        (0.001, \"*** Highly significant difference\"),\n",
    "        (0.01, \"** More significant difference\"),\n",
    "        (0.05, \"* Significant difference\"),\n",
    "    ]\n",
    "\n",
    "    for threshold, label in levels:\n",
    "        if p_value <= threshold:\n",
    "            return label\n",
    "\n",
    "    return \"Not significant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall test for all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY SCORES: MALES X FEMALES\")\n",
    "\n",
    "print(\"BASELINE\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_ACC\"], df_base_cond[\"PRIV_ACC\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\nSEPARATION\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_sep_cond[\"UNP_ACC\"], df_sep_cond[\"PRIV_ACC\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\nINDEPENDENCE\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_ind_cond[\"UNP_ACC\"], df_ind_cond[\"PRIV_ACC\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\nSUFFICIENCY\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_suf_cond[\"UNP_ACC\"], df_suf_cond[\"PRIV_ACC\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"F1_MACRO\"], df_sep[\"F1_MACRO\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"F1_MACRO\"], df_ind[\"F1_MACRO\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"F1_MACRO\"], df_suf[\"F1_MACRO\"])\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"AVG_ODDS_DIFF\"], df_sep[\"AVG_ODDS_DIFF\"])\n",
    "\n",
    "print(\"Baseline X Ind AVG_ODDS_DIFF\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"EQ_OPP_DIFF\"], df_sep[\"EQ_OPP_DIFF\"])\n",
    "\n",
    "print(\"Baseline X Ind EQ_ODDS_DIFF\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_FNR\"], df_base_cond[\"PRIV_FNR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female FNR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_sep_cond[\"UNP_FNR\"], df_sep_cond[\"PRIV_FNR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female FNR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_FPR\"], df_base_cond[\"PRIV_FPR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female FPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_sep_cond[\"UNP_FPR\"], df_sep_cond[\"PRIV_FPR\"])\n",
    "\n",
    "print(\"Separation (Thre.Opt): Males x Female FPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_TPR\"], df_base_cond[\"PRIV_TPR\"])\n",
    "\n",
    "print(\"Separation (Thre.Opt): Males x Female TPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_sep_cond[\"UNP_TPR\"], df_sep_cond[\"PRIV_TPR\"])\n",
    "\n",
    "print(\"Separation (Thre.Opt): Males x Female TPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_TNR\"], df_base_cond[\"PRIV_TNR\"])\n",
    "\n",
    "print(\"Separation (Thre.Opt): Males x Female TNR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_sep_cond[\"UNP_TNR\"], df_sep_cond[\"PRIV_TNR\"])\n",
    "\n",
    "print(\"Separation (Thre.Opt): Males x Female TNR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the separation evaluation - post process\n",
    "# fmt: off\n",
    "conditional_rates_per_group = [\n",
    "    # \"UNP_TPR\", \"PRIV_TPR\",\n",
    "    # \"UNP_TNR\", \"PRIV_TNR\",\n",
    "    \"UNP_FPR\", \"PRIV_FPR\",\n",
    "    \"UNP_FNR\", \"PRIV_FNR\"\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "for metric in conditional_rates_per_group:\n",
    "    group = \"females\" if metric.startswith(\"UNP_\") else \"males\"\n",
    "\n",
    "    metric_mean = df_base_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_base_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"BASELINE: {metric} - {group}: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\")\n",
    "\n",
    "    metric_mean = df_sep_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_sep_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"SEPARATION - Threshold Opt.: {metric} - {group}: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDEPENDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base[\"STAT_PAR_DIFF\"], df_ind[\"STAT_PAR_DIFF\"])\n",
    "\n",
    "print(\"Baseline X Ind STAT_PAR_DIFF\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_TPR\"], df_base_cond[\"PRIV_TPR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female TPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_ind_cond[\"UNP_TPR\"], df_ind_cond[\"PRIV_TPR\"])\n",
    "\n",
    "print(\"Indenpendece: Males x Female TPR\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEPENDENCE\n",
    "conditional_rates_per_group = [\"UNP_TPR\", \"PRIV_TPR\"]\n",
    "\n",
    "for metric in conditional_rates_per_group:\n",
    "    group = \"females\" if metric.startswith(\"UNP_\") else \"males\"\n",
    "\n",
    "    metric_mean = df_base_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_base_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"BASELINE: {metric} - {group}: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\")\n",
    "\n",
    "    metric_mean = df_ind_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_ind_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"INDEPENDENCE - Reweighing: {metric} - {group}: {metric_mean:.3f} $\\pm$ {lower_ci:.3f}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomance of the separation evaluation - post process\n",
    "# fmt: off\n",
    "conditional_rates_per_group = [\n",
    "    \"UNP_PPV\", \"PRIV_PPV\",\n",
    "    \"UNP_NPV\", \"PRIV_NPV\"\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "for metric in conditional_rates_per_group:\n",
    "    group = \"females\" if metric.startswith(\"UNP_\") else \"males\"\n",
    "\n",
    "    metric_mean = df_base_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_base_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"BASELINE: {metric} - {group}: {metric_mean:.4f} $\\pm$ {lower_ci:.3f}\")\n",
    "\n",
    "    metric_mean = df_suf_cond[metric].mean()\n",
    "    ci = get_confidence_interval(df_suf_cond[metric])\n",
    "    lower_ci = np.abs(metric_mean - ci[0])\n",
    "    upper_ci = np.abs(metric_mean - ci[1])\n",
    "    print(f\"SUFFICIENCY - Calibration.: {metric} - {group}: {metric_mean:.4f} $\\pm$ {lower_ci:.3f}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferença não significante, que não alterou de forma significativa os falsos positivos e negativos do modelo. \n",
    "# Mantendo a calibração já existente do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_PPV\"], df_base_cond[\"PRIV_PPV\"])\n",
    "\n",
    "print(\"Baseline: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_suf_cond[\"UNP_PPV\"], df_suf_cond[\"PRIV_PPV\"])\n",
    "\n",
    "print(\"Suffiency: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_FOR\"], df_base_cond[\"PRIV_FOR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_suf_cond[\"UNP_FOR\"], df_suf_cond[\"PRIV_FOR\"])\n",
    "\n",
    "print(\"Suffiency: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_FDR\"], df_base_cond[\"PRIV_FDR\"])\n",
    "\n",
    "print(\"Baseline: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_suf_cond[\"UNP_FDR\"], df_suf_cond[\"PRIV_FDR\"])\n",
    "\n",
    "print(\"Suffiency: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_base_cond[\"UNP_NPV\"], df_base_cond[\"PRIV_NPV\"])\n",
    "\n",
    "print(\"Baseline: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))\n",
    "\n",
    "print(\"\\n##############################################\")\n",
    "t_test_pvalue, mannwhitney_pvalue = p_value_test(df_suf_cond[\"UNP_NPV\"], df_suf_cond[\"PRIV_NPV\"])\n",
    "\n",
    "print(\"Suffiency: Males x Female\")\n",
    "print(\"t-test significance level:\", significance_level(t_test_pvalue))\n",
    "print(\"mannwhitney significance level:\", significance_level(mannwhitney_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
